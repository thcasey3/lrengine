from sklearn import ensemble, tree, neural_network, neighbors, gaussian_process
import numpy as np

ANOMALIES_PARAMS = {
    "detect_func": None,
    "detect_func_params": None,
    "fit_func": None,
    "fit_func_params": None,
    "k": 1,
    "c": 3.0,
    "side": "both",
    "high": 0.995,
    "low": 0.005,
    "support_fraction": None,
    "window": 3,
    "n_steps": 1,
    "step_size": 1,
    "contamination": 0.025,
    "target": "series",
    "n_clusters": 3,
    "min_periods": None,
    "agg": "median",
    "trend": False,
    "freq": None,
    "ts_linewidth": 1,
    "ts_markersize": 3,
    "anomaly_markersize": 5,
    "anomaly_color": "red",
    "anomaly_tag": "marker",
    "curve_group": "all",
    "figsize": (12, 6),
    "random_state": 42,
    "time_range": None,
}

TIMESERIES_PARAMS = {
    "target": "log",
    "order": (1, 1, 1),
    "opt_order": True,
    "pdq_limits": ((0, 2), (0, 2), (0, 2)),
    "seasonal_order": (0, 0, 0, 0),
    "opt_seasonal_order": False,
    "PDQs_limits": ((0, 1), (0, 1), (0, 1), (2, 52)),
    "trend": "n",
    "opt_trend": False,
    "trend_list": ("n", "c", "t", "ct"),
    "ic": "aicc",
    "log_lambda": 0,
    "freq": "W",
    "time_range": None,
    "encode": True,
    "scale": False,
    "normalize": False,
    "group": "mean",
    "aggregate": "mean",
    "resample": "mean",
    "interpolate": "time",
    "outliers": {"remove": 0.25},
    "model": "additive",
    "method": "nm",
    "period": None,
    "filt": None,
    "two_sided": True,
    "extrapolate_trend": 0,
    "metric": "mape",
    "alpha": 0.05,
}

LEARNING_PARAMS = {
    "model_selection": "regress",
    "Xcolumns": [],
    "ycolumn": [],
    "split_column": {},
    "metric": ["mape"],
    "outliers": {"remove": 0.025},
    "normalize": False,
    "drop_uniform": False,
    "handle_na": "fill",
    "test_size": 0.1,
    "n_jobs": -1,
    "random_state": 42,
    "verbose": False,
    "bootstrap": False,
    "encode_X": True,
    "scale": "robust",
    "decode": False,
}

REGRESSING_PARAMS = {
    "method": ["RandomForest"],
    "encode_y": False,
    "loss_a": "square",
    "loss_g": "squared_error",
    "loss_h": "squared_error",
    "weights": "distance",
    "criterion": "squared_error",
    "n_estimators": 200,  # {"auto": 3},
    "max_features": "auto",
    "max_samples": None,
    "min_samples_split": 2,
    "max_depth": None,
    "min_samples_leaf": 1,
    "min_weight_fraction_leaf": 0.0,
    "max_leaf_nodes": None,
    "min_impurity_decrease": 0.0,
    "bootstrap": True,
    "oob_score": False,
    "verbose": 0,
    "warm_start": False,
    "ccp_alpha": 0.0,
    "activation": "logistic",
    "solver": "adam",
    "learning_rate": "adaptive",
    "learning_rate_init": 0.001,
    "power_t": 0.5,
    "l2_regularization": 1,
    "hidden_layer_sizes": (100),
    "alpha": 0.0001,
    "batch_size": "auto",
    "max_iter": 200,
    "shuffle": True,
    "tol": 0.0001,
    "momentum": 0.9,
    "nesterovs_momentum": True,
    "early_stopping": False,
    "validation_fraction": 0.1,
    "beta_1": 0.9,
    "beta_2": 0.999,
    "epsilon": 1e-08,
    "n_iter_no_change": 10,
    "max_fun": 15000,
    "feature_select": False,
    "base_estimator": ensemble.RandomForestRegressor(random_state=42),
    "estimators": [
        ("dt", tree.DecisionTreeRegressor(random_state=42)),
        ("ext", tree.ExtraTreeRegressor(random_state=42)),
        (
            "ab",
            ensemble.AdaBoostRegressor(
                base_estimator=ensemble.RandomForestRegressor(),
                loss="square",
                random_state=42,
            ),
        ),
        (
            "ba",
            ensemble.BaggingRegressor(
                base_estimator=ensemble.RandomForestRegressor(), random_state=42
            ),
        ),
        ("exts", ensemble.ExtraTreesRegressor(random_state=42)),
        ("hgb", ensemble.HistGradientBoostingRegressor(random_state=42)),
        ("gb", ensemble.GradientBoostingRegressor(random_state=42)),
        ("rf", ensemble.RandomForestRegressor(random_state=42)),
        ("mlp", neural_network.MLPRegressor(random_state=42)),
        ("kn", neighbors.KNeighborsRegressor(weights="distance")),
        ("gp", gaussian_process.GaussianProcessRegressor(random_state=42)),
    ],
    "final_estimator": ensemble.RandomForestRegressor(random_state=42),
}

CLASSIFYING_PARAMS = {
    "method": ["RandomForest"],
    "encode_y": True,
    "loss_a": "square",
    "loss_g": "deviance",
    "loss_h": "auto",
    "weights": "distance",
    "criterion": "gini",
    "criterion_g": "squared_error",
    "n_estimators": {"auto": 10},
    "max_features": "auto",
    "max_samples": None,
    "activation": "logistic",
    "solver": "adam",
    "learning_rate": "adaptive",
    "learning_rate_init": 0.001,
    "power_t": 0.5,
    "l2_regularization": 1,
    "feature_select": False,
    "base_estimator": ensemble.RandomForestClassifier(random_state=42),
    "estimators": [
        ("dt", tree.DecisionTreeClassifier(random_state=42)),
        ("ext", tree.ExtraTreeClassifier(random_state=42)),
        (
            "ab",
            ensemble.AdaBoostClassifier(
                base_estimator=ensemble.RandomForestClassifier(),
                random_state=42,
            ),
        ),
        (
            "ba",
            ensemble.BaggingClassifier(
                base_estimator=ensemble.RandomForestClassifier(), random_state=42
            ),
        ),
        ("exts", ensemble.ExtraTreesClassifier(random_state=42)),
        ("hgb", ensemble.HistGradientBoostingClassifier(random_state=42)),
        ("gb", ensemble.GradientBoostingClassifier(random_state=42)),
        ("rf", ensemble.RandomForestClassifier(random_state=42)),
        ("mlp", neural_network.MLPClassifier(random_state=42)),
        ("kn", neighbors.KNeighborsClassifier(weights="distance")),
        ("gp", gaussian_process.GaussianProcessClassifier(random_state=42)),
    ],
    "final_estimator": ensemble.RandomForestClassifier(random_state=42),
}

CLUSTERING_PARAMS = {
    "method": ["Kmeans"],
    "encode_y": False,
    "eigen_solver": None,
    "n_clusters": 8,
    "n_components": None,
    "n_best": 3,
    "gamma": 1.0,
    "n_neighbors": 10,
    "eigen_tol": 0.0,
    "assign_labels": "kmeans",
    "degree": 3,
    "coef0": 1,
    "kernel_params": None,
    "svd_method": "randomized",
    "n_svd_vecs": None,
    "mini_batch": False,
    "copy_x": True,
    "min_samples": 5,
    "max_eps": np.inf,
    "metric": "minkowski",
    "p": 2,
    "metric_params": None,
    "cluster_method": "xi",
    "eps": 0.5,
    "xi": 0.05,
    "predecessor_correction": True,
    "min_cluster_size": None,
    "algorithm": "auto",
    "leaf_size": 30,
    "damping": 0.5,
    "convergence_iter": 15,
    "preference": None,
    "threshold": 0.5,
    "branching_factor": 50,
    "copy": True,
    "tol": 0.0,
    "max_no_improvement": 10,
    "init_size": None,
    "n_init": 3,
    "reassignment_ratio": 0.01,
    "compute_labels": True,
    "init": "k-means++",
    "batch_size": 1024,
    "affinity": "euclidean",
    "memory": None,
    "connectivity": None,
    "compute_full_tree": "auto",
    "linkage": "ward",
    "pooling_func": np.mean,
    "distance_threshold": None,
    "compute_distances": False,
    "max_iter": 300,
    "bandwidth": None,
    "seeds": None,
    "bin_seeding": False,
    "min_bin_freq": 1,
    "cluster_all": True,
}

SEMI_SUPERVISED_PARAMS = {
    "method": ["LabelPropagation"],
    "base_estimator": None,
    "threshold": 0.75,
    "criterion": "threshold",
    "k_best": 10,
    "kernel": "rbf",
    "gamma": 20,
    "n_neighbors": 7,
    "alpha": 0.2,
    "max_iter": 30,
    "tol": 0.001,
}

# SITE_PARAMS = {}
# SESSION_PARAMS = {}
